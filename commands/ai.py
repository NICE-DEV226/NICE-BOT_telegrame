"""
NICE-BOT - AI Commands
/ai, /resume, /idee commands using PrinceTech GPT API
"""

import os
import logging
import aiohttp
from telegram import Update
from telegram.ext import ContextTypes
from db import get_user, add_history

logger = logging.getLogger(__name__)

# PrinceTech AI API
PRINCETECH_AI_API = "https://api.princetechn.com/api/ai/gpt"
PRINCETECH_API_KEY = os.getenv("PRINCETECHN_API_KEY", "prince")

async def ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /ai command - AI question answering using PrinceTech GPT"""
    user = update.effective_user
    
    # Log command
    db_user = get_user(str(user.id))
    if db_user:
        add_history(db_user['id'], '/ai', ' '.join(context.args))
    
    if not context.args:
        await update.message.reply_text(
            "‚ùå **Usage :** /ai <question>\n\n"
            "**Exemple :** /ai Comment fonctionne l'intelligence artificielle ?\n"
            "**Exemple :** /ai Explique-moi la photosynth√®se\n"
            "**Exemple :** /ai Quelle est la capitale de la France ?",
            parse_mode='Markdown'
        )
        return
    
    question = ' '.join(context.args)
    
    try:
        # Send typing action
        await update.message.reply_chat_action("typing")
        
        async with aiohttp.ClientSession() as session:
            # Use PrinceTech GPT API
            params = {
                "apikey": PRINCETECH_API_KEY,
                "q": question
            }
            
            async with session.get(PRINCETECH_AI_API, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    # Check if response is successful
                    if data.get('success') and data.get('result'):
                        ai_response = data['result']
                        
                        response_text = f"""
ü§ñ **R√©ponse IA**

**Question :** {question}

**R√©ponse :** {ai_response}

‚ú® *Propuls√© par NICE-BOT AI*
                        """
                        
                        await update.message.reply_text(response_text, parse_mode='Markdown')
                    else:
                        await update.message.reply_text(
                            "ü§ñ D√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse appropri√©e √† votre question.\n"
                            "R√©essayez avec une question diff√©rente.",
                            parse_mode='Markdown'
                        )
                else:
                    await update.message.reply_text("‚ùå Service IA temporairement indisponible. R√©essayez plus tard.")
    
    except Exception as e:
        logger.error(f"AI error: {e}")
        await update.message.reply_text("‚ùå Erreur lors de la g√©n√©ration de la r√©ponse IA.")

async def resume(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /resume command - Text summarization using PrinceTech AI"""
    user = update.effective_user
    
    # Log command
    db_user = get_user(str(user.id))
    if db_user:
        add_history(db_user['id'], '/resume', ' '.join(context.args))
    
    if not context.args:
        await update.message.reply_text(
            "‚ùå **Usage :** /resume <texte √† r√©sumer>\n\n"
            "**Exemple :** /resume L'intelligence artificielle est une technologie qui permet aux machines d'apprendre et de prendre des d√©cisions...",
            parse_mode='Markdown'
        )
        return
    
    text_to_summarize = ' '.join(context.args)
    
    if len(text_to_summarize) < 50:
        await update.message.reply_text("‚ùå Le texte est trop court pour √™tre r√©sum√© (minimum 50 caract√®res).")
        return
    
    try:
        # Send typing action
        await update.message.reply_chat_action("typing")
        
        async with aiohttp.ClientSession() as session:
            # Use PrinceTech GPT API with summarization prompt
            prompt = f"R√©sume ce texte de mani√®re concise et claire: {text_to_summarize}"
            params = {
                "apikey": PRINCETECH_API_KEY,
                "q": prompt
            }
            
            async with session.get(PRINCETECH_AI_API, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    if data.get('success') and data.get('result'):
                        summary = data['result']
                        
                        response_text = f"""
üìù **R√©sum√© automatique**

**Texte original ({len(text_to_summarize)} caract√®res) :**
{text_to_summarize[:200]}{'...' if len(text_to_summarize) > 200 else ''}

**R√©sum√© ({len(summary)} caract√®res) :**
{summary}

‚ú® *R√©sum√© g√©n√©r√© par NICE-BOT AI*
                        """
                        
                        await update.message.reply_text(response_text, parse_mode='Markdown')
                    else:
                        await update.message.reply_text("‚ùå Impossible de g√©n√©rer un r√©sum√© pour ce texte.")
                else:
                    await update.message.reply_text("‚ùå Service de r√©sum√© temporairement indisponible.")
    
    except Exception as e:
        logger.error(f"Summarization error: {e}")
        await update.message.reply_text("‚ùå Erreur lors de la g√©n√©ration du r√©sum√©.")

async def idee(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /idee command - Idea generation using PrinceTech AI"""
    user = update.effective_user
    
    # Log command
    db_user = get_user(str(user.id))
    if db_user:
        add_history(db_user['id'], '/idee', ' '.join(context.args))
    
    if not context.args:
        await update.message.reply_text(
            "‚ùå **Usage :** /idee <sujet>\n\n"
            "**Exemple :** /idee application mobile\n"
            "**Exemple :** /idee projet weekend\n"
            "**Exemple :** /idee cadeau anniversaire",
            parse_mode='Markdown'
        )
        return
    
    topic = ' '.join(context.args)
    
    try:
        # Send typing action
        await update.message.reply_chat_action("typing")
        
        async with aiohttp.ClientSession() as session:
            # Use PrinceTech GPT API with idea generation prompt
            prompt = f"Donne-moi 5 id√©es cr√©atives et originales pour: {topic}"
            params = {
                "apikey": PRINCETECH_API_KEY,
                "q": prompt
            }
            
            async with session.get(PRINCETECH_AI_API, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    if data.get('success') and data.get('result'):
                        ideas = data['result']
                        
                        response_text = f"""
üí° **G√©n√©rateur d'id√©es**

**Sujet :** {topic}

**Id√©es g√©n√©r√©es par IA :**
{ideas}

‚ú® *Propuls√© par NICE-BOT AI - Laissez libre cours √† votre cr√©ativit√© !*
                        """
                        
                        await update.message.reply_text(response_text, parse_mode='Markdown')
                    else:
                        # Fallback to predefined ideas
                        response_text = await generate_fallback_ideas(topic)
                        await update.message.reply_text(response_text, parse_mode='Markdown')
                else:
                    # Fallback to predefined ideas
                    response_text = await generate_fallback_ideas(topic)
                    await update.message.reply_text(response_text, parse_mode='Markdown')
    
    except Exception as e:
        logger.error(f"Idea generation error: {e}")
        # Fallback to predefined ideas
        response_text = await generate_fallback_ideas(topic)
        await update.message.reply_text(response_text, parse_mode='Markdown')

async def generate_fallback_ideas(topic: str) -> str:
    """Generate fallback ideas when AI is not available"""
    
    # Predefined idea templates based on common topics
    idea_templates = {
        'app': [
            "Application de suivi des habitudes quotidiennes",
            "App de partage de recettes entre voisins",
            "Outil de gestion de budget personnel",
            "App de m√©ditation guid√©e",
            "Plateforme d'√©change de services locaux"
        ],
        'projet': [
            "Cr√©er un blog sur votre passion",
            "Organiser un √©v√©nement communautaire",
            "D√©velopper une comp√©tence cr√©ative",
            "Lancer un potager urbain",
            "Cr√©er une cha√Æne YouTube √©ducative"
        ],
        'cadeau': [
            "Exp√©rience personnalis√©e (cours, atelier)",
            "Album photo avec souvenirs partag√©s",
            "Objet fait main avec une touche personnelle",
            "Abonnement √† un service qu'ils aiment",
            "Journ√©e d'activit√©s surprises"
        ]
    }
    
    # Find matching category
    topic_lower = topic.lower()
    selected_ideas = []
    
    for category, ideas in idea_templates.items():
        if category in topic_lower:
            selected_ideas = ideas
            break
    
    # Default generic ideas
    if not selected_ideas:
        selected_ideas = [
            f"Rechercher les tendances actuelles en {topic}",
            f"Cr√©er une communaut√© autour de {topic}",
            f"D√©velopper un guide pratique sur {topic}",
            f"Organiser un √©v√©nement li√© √† {topic}",
            f"Innover en combinant {topic} avec la technologie"
        ]
    
    ideas_text = "\n".join([f"{i+1}. {idea}" for i, idea in enumerate(selected_ideas)])
    
    return f"""
üí° **G√©n√©rateur d'id√©es**

**Sujet :** {topic}

**Id√©es sugg√©r√©es :**
{ideas_text}

*Id√©es pr√©d√©finies - Personnalisez-les selon vos besoins !*
    """
